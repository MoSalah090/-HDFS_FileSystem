# HDFS_FileSystem

OPEN THE REEDME FILE
What is MapReduce?
MapReduce is a processing technique and a program model for distributed computing based on java. The MapReduce algorithm contains two important tasks, namely Map and Reduce. Map takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs). Secondly, reduce task, which takes the output from a map as an input and combines those data tuples into a smaller set of tuples. As the sequence of the name MapReduce implies, the reduce task is always performed after the map job.

The major advantage of MapReduce is that it is easy to scale data processing over multiple computing nodes. Under the MapReduce model, the data processing primitives are called mappers and reducers. Decomposing a data processing application into mappers and reducers is sometimes nontrivial. But, once we write an application in the MapReduce form, scaling the application to run over hundreds, thousands, or even tens of thousands of machines in a cluster is merely a configuration change. This simple scalability is what has attracted many programmers to use the MapReduce model

===================================================================================================================
USED APPS: CLOUDERA-WINSCP-visual studio code

<=USE THE FOLLOWING COMMEND TO AVOIDE ANY ERRORS=>

# ---------------------------HDFS-------------------------------------------

hdfs dfs -mkdir -p /user/cloudera/input
vi sample_input.txt
Press i
Paste the text you want as :
What do you mean by Object
What do you know about Java
What is Java Virtual Machine
How Java enabled High Performance
Press Esc then :wq! then Enter
=============================================================================

## Make sure that the file created by using the command : cat sample_input.txt

hdfs dfs -put sample_input.txt /user/cloudera/input

## Make sure that the file loaded and stored into HDFS :

hdfs dfs -ls /user/cloudera/input/

hdfs dfs -cat /user/cloudera/input/sample_input.txt

=============================================================================
su root
cloudera

hdfs fsck /user/cloudera/input -files -blocks -locations
=====USE YOUR BLOCK DONT COPY THE FOLLWING BLK
blk_1073742232_1410

find / -name blk_1073742232\* -print
===USE YOUR LINK
/var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-286282631-127.0.0.1-1433865208026/current/finalized/subdir0/subdir1/blk_1073742232_1410.meta

ls -ltr /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-286282631-127.0.0.1-1433865208026/current/finalized/subdir0/subdir1/blk_1073742232\*

cat /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-286282631-127.0.0.1-1433865208026/current/finalized/subdir0/subdir1/blk_1073742232

---------------------------Map Reduce-------------------------------------------

mkdir /home/cloudera/word_count_job

export LIB_PATH=/usr/lib/hadoop
export JARS=$LIB_PATH/client-0.20/hadoop-core.jar:$LIB_PATH/lib/commons-cli-1.2.jar:$LIB_PATH/client/hadoop-common.jar:$LIB_PATH/hadoop-annotations-2.6.0-cdh5.4.2.jar
======= GO CD YOUR FOLDE WORDCURRENT JOB NAD THE RUN THE COMMENDS
javac -classpath $JARS wordcount_classes/WordCount.java

jar -cvf wordcount.jar -C wordcount_classes/ .

hadoop jar wordcount.jar WordCount /user/cloudera/input /user/cloudera/output
